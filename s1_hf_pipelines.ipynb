{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy langchain-core langchain-community langchain-chroma transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Similar to RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.Realm Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thigazholim/anaconda3/envs/py311_personal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import RealmConfig, RealmEmbedder \n",
    "\n",
    "configuration = RealmConfig()\n",
    "model = RealmEmbedder(configuration)\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RealmConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu_new\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_span_width\": 10,\n",
       "  \"model_type\": \"realm\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_block_records\": 13353718,\n",
       "  \"num_candidates\": 8,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"reader_beam_size\": 5,\n",
       "  \"reader_layer_norm_eps\": 0.001,\n",
       "  \"reader_seq_len\": 320,\n",
       "  \"retriever_proj_size\": 128,\n",
       "  \"searcher_beam_size\": 5000,\n",
       "  \"span_hidden_size\": 256,\n",
       "  \"transformers_version\": \"4.45.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.RealmTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thigazholim/anaconda3/envs/py311_personal/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import RealmTokenizer \n",
    "text = [[\"Hello world!\", \"Nice to meet you!\"], [\"The cute cat.\", \"The adorable dog.\"]]\n",
    "\n",
    "model_name = \"google/realm-cc-news-pretrained-encoder\"\n",
    "tokenizer = RealmTokenizer.from_pretrained(model_name)\n",
    "tokenized_text = tokenizer.batch_encode_candidates(text, max_length = 10, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.RealmTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RealmTokenizerFast \n",
    "\n",
    "text = [[\"Hello world!\", \"Nice to meet you!\"], [\"The cute cat.\", \"The adorable dog.\"]]\n",
    "\n",
    "tokenizer = RealmTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "tokenized_text = tokenizer.batch_encode_candidates(text, max_length = 10, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.RealmRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, RealmEmbedder \n",
    "import torch \n",
    "\n",
    "model_name = \"google/realm-cc-news-pretrained-embedder\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = RealmEmbedder.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer(\"Hello my dog is cute\", return_tensors = \"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "projected_score = outputs.projected_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RealmEmbedderOutput(projected_score=tensor([[ 0.0104,  0.1440, -0.2996, -0.0171, -0.2020,  0.3074,  0.1743,  0.0951,\n",
       "          0.0742,  0.2060, -0.2306,  0.1745,  0.0702,  0.0442, -0.0107, -0.1233,\n",
       "          0.2895,  0.1332,  0.2101, -0.2831,  0.1967, -0.2140, -0.2875, -0.1658,\n",
       "         -0.0781, -0.1009, -0.1484,  0.1377, -0.0052,  0.1274, -0.1648, -0.2175,\n",
       "         -0.0926,  0.1561, -0.1623,  0.0720, -0.1116,  0.0968, -0.2673,  0.1744,\n",
       "          0.1238, -0.1646, -0.1151, -0.2973,  0.0232,  0.2000,  0.0569, -0.0054,\n",
       "         -0.1775,  0.0825,  0.0477,  0.0840, -0.0737,  0.2533,  0.0917, -0.3854,\n",
       "         -0.2690, -0.1063, -0.1390, -0.1299,  0.3417,  0.1054, -0.3920,  0.2655,\n",
       "          0.0299,  0.0093, -0.1478, -0.1488,  0.1248,  0.1710,  0.1008, -0.0475,\n",
       "          0.1224,  0.3072, -0.0770,  0.2762, -0.2797,  0.0218,  0.0072, -0.0360,\n",
       "         -0.1487,  0.0146,  0.0945,  0.1217,  0.2518,  0.1535, -0.0093,  0.1245,\n",
       "         -0.1556,  0.0351, -0.4017, -0.0254, -0.0615,  0.2113,  0.0956, -0.1376,\n",
       "          0.0231,  0.0536, -0.1211, -0.0833, -0.0476,  0.0366,  0.0625,  0.3067,\n",
       "          0.3454,  0.0094, -0.0043, -0.2453, -0.2147, -0.0151, -0.2927, -0.1324,\n",
       "          0.0438,  0.3203, -0.0489,  0.0260, -0.0149,  0.0101, -0.0330,  0.2523,\n",
       "          0.2101, -0.1743,  0.1628,  0.1698, -0.1769,  0.2252, -0.2581,  0.1990]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.RealmScorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/realm-cc-news-pretrained-scorer were not used when initializing RealmScorer: ['query_embedder.realm.embeddings.position_ids']\n",
      "- This IS expected if you are initializing RealmScorer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RealmScorer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6536, 0.3909],\n",
       "        [0.3008, 0.2741]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from transformers import AutoTokenizer, RealmScorer \n",
    "\n",
    "model_name = \"google/realm-cc-news-pretrained-scorer\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "model = RealmScorer.from_pretrained(model_name, num_candidates =2)\n",
    "\n",
    "input_texts = [\"How are you?\", \"What is the item in the picture?\"]\n",
    "candidates_texts = [[\"Hello world!\", \"Nice to meet you!\"], [\"A cute cat.\", \"An adorable dog.\"]]\n",
    "\n",
    "inputs = tokenizer(input_texts, return_tensors = \"pt\", padding = True)\n",
    "candidates_inputs = tokenizer.batch_encode_candidates(candidates_texts, max_length = 10, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(\n",
    "    **inputs, \n",
    "    candidate_input_ids = candidates_inputs.input_ids, \n",
    "    candidate_attention_mask = candidates_inputs.attention_mask, \n",
    "    candidate_token_type_ids = candidates_inputs.token_type_ids,\n",
    ")\n",
    "\n",
    "relevance_score= outputs.relevance_score \n",
    "relevance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RealmScorerOutput(relevance_score=tensor([[0.6536, 0.3909],\n",
       "        [0.3008, 0.2741]], grad_fn=<ViewBackward0>), query_score=tensor([[-9.9364e-02,  1.9061e-02, -1.1568e-01, -2.4949e-03,  5.2143e-02,\n",
       "          3.2825e-02,  9.0304e-02,  8.8276e-02, -4.8526e-02, -5.8189e-02,\n",
       "         -4.8693e-02,  5.9679e-02,  2.7601e-02, -7.4258e-03, -1.0389e-02,\n",
       "          3.7499e-02, -6.7484e-02,  3.5330e-02,  6.4482e-02, -1.8363e-02,\n",
       "         -4.6311e-02, -4.0528e-02, -4.3615e-03, -9.2813e-02, -8.6109e-02,\n",
       "          1.9582e-02, -1.2501e-01, -1.3312e-02,  1.4748e-02, -1.3577e-02,\n",
       "         -3.0497e-02, -5.4675e-03, -2.9807e-02, -1.4008e-02, -1.1179e-01,\n",
       "          8.3566e-02, -1.7059e-02,  2.0392e-02, -6.7560e-03,  1.0769e-02,\n",
       "         -5.6942e-02, -3.7400e-02, -6.4183e-02, -5.9047e-02,  2.3588e-02,\n",
       "          7.9742e-02,  5.8374e-02,  5.3356e-02,  3.0724e-02,  6.6851e-02,\n",
       "          7.1329e-02, -1.0509e-01, -3.7729e-02,  1.5201e-02, -9.1713e-03,\n",
       "         -9.0360e-02, -1.1937e-01, -4.9125e-02,  7.3877e-02, -1.0096e-01,\n",
       "          5.3921e-02, -4.5865e-02, -8.4641e-02,  1.2743e-01,  3.1242e-02,\n",
       "          4.2682e-02, -7.4076e-02, -6.5742e-02, -4.6972e-02,  7.7475e-02,\n",
       "          6.1789e-02, -2.4389e-02, -1.4037e-02,  3.5231e-02,  4.0180e-04,\n",
       "          6.3727e-02, -1.9123e-02, -4.4634e-03,  6.4431e-02, -3.6184e-02,\n",
       "         -3.7824e-02, -3.3290e-02, -6.2111e-02,  4.0980e-02,  4.2816e-02,\n",
       "          2.4769e-02,  1.6615e-03,  6.7950e-02, -6.4690e-02,  2.7509e-02,\n",
       "         -5.1800e-02, -8.9353e-02, -4.5937e-02,  1.2368e-02,  6.0254e-02,\n",
       "          1.8561e-02,  4.1165e-02,  5.4440e-02, -8.0006e-02, -9.5911e-03,\n",
       "         -4.8108e-02,  1.0713e-01,  6.8687e-03,  4.9239e-02,  1.0312e-01,\n",
       "         -9.4652e-03,  8.6207e-02, -4.3618e-02, -4.0665e-02,  1.4167e-01,\n",
       "         -2.3196e-02,  1.6964e-02,  2.9711e-02,  8.1194e-02, -5.0432e-02,\n",
       "          5.9226e-03, -1.4839e-02,  1.1103e-02,  5.0082e-02, -4.4462e-02,\n",
       "         -3.5462e-03,  6.7864e-02,  1.2422e-01,  7.6224e-02, -5.3535e-02,\n",
       "          8.3056e-02, -3.6629e-02,  5.5344e-02],\n",
       "        [-5.3994e-02,  6.9631e-02, -1.9729e-03, -2.0552e-02, -1.6617e-03,\n",
       "          2.6707e-02,  3.0320e-02,  3.4940e-02, -9.1255e-03,  6.0928e-02,\n",
       "         -4.2752e-02,  1.9436e-02,  1.0205e-01,  2.9995e-02, -1.0344e-02,\n",
       "          2.9946e-02, -6.4208e-02, -1.5277e-02,  7.9548e-02, -3.0787e-02,\n",
       "         -4.0793e-02, -6.0203e-02, -4.2954e-02, -3.8559e-02, -1.2891e-01,\n",
       "         -1.8586e-02, -7.5617e-02, -2.6528e-02, -1.8158e-02,  4.5766e-03,\n",
       "         -2.8368e-02,  1.4333e-02,  4.8632e-02, -3.5223e-02, -8.8247e-02,\n",
       "          2.8568e-02,  1.1276e-02,  2.1671e-02, -7.5038e-03,  4.7930e-02,\n",
       "         -6.9233e-02, -4.1602e-02, -1.3550e-01, -6.2653e-02,  2.3815e-02,\n",
       "         -4.6885e-02,  6.5905e-03,  1.4093e-01, -3.5221e-02,  8.2586e-02,\n",
       "         -1.3501e-03, -4.9618e-02,  1.3252e-02, -1.0787e-02,  2.2894e-02,\n",
       "         -1.5000e-01, -7.7307e-02, -4.3325e-02,  4.6871e-02, -2.3480e-02,\n",
       "          7.2490e-02,  3.1070e-02, -7.0216e-02,  8.5822e-02,  3.1377e-02,\n",
       "          1.1603e-02, -1.0637e-01, -7.7501e-02, -4.5072e-02,  4.0953e-02,\n",
       "          5.8318e-02,  4.1807e-02,  7.3712e-02, -3.4818e-02,  4.0808e-02,\n",
       "         -4.8924e-02,  9.7028e-05, -4.1502e-02, -1.9488e-02, -3.5821e-02,\n",
       "         -3.6573e-02,  4.4720e-02,  2.9540e-02,  5.2712e-02,  5.5177e-02,\n",
       "          4.2053e-02,  6.7151e-02,  4.9721e-02,  1.2243e-02, -3.1286e-03,\n",
       "         -4.1058e-02, -1.1552e-01, -4.2701e-02,  1.7724e-02,  4.4099e-02,\n",
       "         -2.4304e-02, -5.1361e-02,  5.4607e-02, -7.0753e-02, -9.8744e-03,\n",
       "         -4.8008e-02,  8.4704e-02,  2.6859e-02,  1.4096e-02,  9.2590e-02,\n",
       "         -9.5734e-02,  2.7748e-02, -1.7746e-02, -2.8844e-02,  7.2774e-02,\n",
       "          9.8827e-03,  5.5080e-02,  8.3246e-02,  8.5258e-02, -4.5427e-02,\n",
       "         -1.2414e-02, -1.4653e-02,  1.1267e-02, -3.6975e-02,  1.7912e-02,\n",
       "          3.5844e-03,  1.5005e-02,  3.9197e-02,  5.7401e-02,  2.4508e-02,\n",
       "          2.6150e-02, -4.3232e-03,  6.9485e-02]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), candidate_score=tensor([[[-2.6646e-01,  2.0471e-01, -3.8031e-02,  1.9455e-01,  1.7271e-01,\n",
       "           2.1211e-01, -1.4862e-01,  2.5247e-01, -2.8454e-02, -1.2355e-02,\n",
       "           1.5501e-01,  6.4473e-02, -6.4847e-03,  2.9435e-01, -1.0224e-02,\n",
       "          -7.7480e-02,  6.2962e-02,  2.2051e-01,  2.5983e-01, -4.5853e-02,\n",
       "           8.2539e-02, -1.3319e-01,  1.4718e-02,  1.4414e-01, -4.7277e-01,\n",
       "          -2.4853e-01, -2.8606e-01,  2.5637e-02, -9.5628e-02, -1.1390e-01,\n",
       "          -5.3042e-02, -5.9713e-02, -6.7267e-02, -8.7105e-02, -1.2566e-01,\n",
       "           1.1465e-02,  1.6081e-01,  7.4640e-02,  3.4204e-03, -7.1356e-02,\n",
       "          -4.4459e-02,  1.4206e-01, -1.0767e-01, -2.7521e-01,  2.3619e-02,\n",
       "           2.7438e-01,  2.0271e-01, -3.2161e-01,  4.4061e-02,  9.2040e-02,\n",
       "          -6.1931e-02, -3.3821e-01, -3.1254e-02, -3.0198e-02,  1.5681e-01,\n",
       "          -1.3428e-01, -2.3412e-01, -1.9951e-01, -2.4735e-01, -3.2113e-01,\n",
       "           1.6783e-01,  5.5159e-02, -7.8645e-02,  2.4550e-01,  3.0416e-02,\n",
       "          -4.3160e-02, -8.9017e-02, -6.6793e-03, -9.4342e-02,  2.5953e-01,\n",
       "          -6.3446e-02, -2.2537e-01, -1.2363e-01,  1.2653e-01, -2.9076e-02,\n",
       "           1.6505e-01, -1.2904e-01,  1.0662e-01, -8.6425e-04, -3.5611e-02,\n",
       "          -3.7989e-01, -7.7906e-02, -3.1281e-01,  1.2756e-01,  1.5157e-01,\n",
       "           1.2535e-01, -9.1064e-02, -1.0390e-02,  6.9124e-02,  6.4374e-02,\n",
       "          -3.3294e-01, -1.2345e-01,  7.5637e-02, -2.8788e-02,  6.0391e-02,\n",
       "          -1.3819e-01,  5.7489e-02,  5.4077e-02, -2.0092e-02, -5.0927e-02,\n",
       "          -4.7222e-02,  3.5176e-01,  1.6764e-01,  1.6956e-01,  1.1958e-01,\n",
       "          -7.1915e-02,  3.2904e-02,  8.9039e-03, -1.8796e-01,  2.1753e-01,\n",
       "          -2.0752e-03, -1.1683e-01,  3.9031e-01,  2.2632e-01, -1.1000e-01,\n",
       "           2.8907e-01, -1.4349e-02,  1.0607e-02, -7.4799e-02,  4.5936e-02,\n",
       "          -1.0517e-01,  4.5606e-01,  1.0358e-01,  6.2613e-03,  1.3714e-01,\n",
       "           7.3970e-02, -2.2575e-01,  1.4806e-02],\n",
       "         [-7.6945e-02,  3.4602e-02, -1.1898e-01, -3.7785e-02,  3.9295e-02,\n",
       "           5.8497e-02,  7.4743e-02,  4.1178e-02, -3.7860e-02, -8.9837e-02,\n",
       "          -6.6770e-02,  7.5701e-02,  7.6192e-02, -1.2590e-02, -1.0274e-02,\n",
       "           3.8874e-02, -4.5948e-02, -1.3109e-02,  1.1966e-01,  2.8859e-02,\n",
       "          -3.0227e-02, -5.3172e-02,  1.1934e-02, -2.1733e-02, -9.8930e-02,\n",
       "           3.0543e-02, -8.5733e-02, -5.3387e-02,  4.9234e-02, -5.4332e-02,\n",
       "           1.6620e-03,  3.3605e-02, -8.8688e-02, -6.5889e-02, -8.6451e-02,\n",
       "           7.5986e-02,  3.5998e-02,  5.8875e-02,  1.8582e-02,  1.6794e-02,\n",
       "          -6.9587e-02, -4.2519e-02, -7.9297e-02, -4.0778e-02,  2.3583e-02,\n",
       "           6.5483e-02,  5.2250e-02,  6.0158e-02,  1.8231e-02,  3.4006e-02,\n",
       "           3.9855e-03, -7.9811e-02, -3.6912e-02, -6.6115e-03,  3.2402e-02,\n",
       "          -9.5924e-02, -1.2172e-01, -6.3664e-02,  9.6444e-02, -7.3849e-02,\n",
       "           5.5363e-02, -4.6284e-02, -4.9699e-02,  1.2253e-01,  3.1345e-02,\n",
       "           3.3592e-04, -8.8845e-02, -8.2692e-02, -3.4261e-02,  8.3905e-02,\n",
       "           9.2738e-02, -2.4597e-02, -5.3750e-02,  4.8440e-02,  1.9405e-02,\n",
       "           3.3864e-02, -4.3325e-02,  2.8190e-02,  6.7035e-02, -3.6143e-02,\n",
       "          -4.5807e-02, -7.2561e-02, -3.1743e-02,  1.6585e-02,  5.6783e-02,\n",
       "           4.5239e-02,  4.2922e-02,  5.8063e-02, -7.0596e-02,  5.7799e-02,\n",
       "          -6.9445e-02, -1.0482e-01, -3.6806e-02,  5.0257e-02,  2.9925e-02,\n",
       "           4.8822e-02,  4.3602e-02,  5.4495e-02, -7.0766e-02, -5.8819e-03,\n",
       "          -4.8032e-02,  6.9831e-02,  7.8651e-02,  6.4225e-02,  9.2326e-02,\n",
       "          -3.7358e-02,  8.7152e-02, -3.6369e-02, -2.2313e-02,  1.1095e-01,\n",
       "          -2.6311e-02, -6.5564e-02,  1.9590e-02,  4.7848e-02, -9.2162e-02,\n",
       "          -2.9134e-02, -1.4843e-02,  1.1195e-02,  8.0052e-03, -5.2746e-02,\n",
       "           1.8697e-02,  5.2883e-02,  3.1755e-02,  1.0306e-01, -4.7939e-02,\n",
       "           5.2082e-02,  1.8910e-03,  8.8019e-02]],\n",
       "\n",
       "        [[-6.4543e-02,  4.8072e-02, -8.9505e-02, -1.1968e-02,  1.0487e-02,\n",
       "           8.9560e-02,  9.3030e-02, -2.3111e-02, -1.3087e-02, -2.8389e-02,\n",
       "          -1.3459e-01,  1.5134e-01,  9.8002e-02, -2.7602e-02, -1.0518e-02,\n",
       "          -2.4244e-02,  3.8907e-02, -4.6829e-02,  1.6597e-01,  6.0363e-02,\n",
       "           8.1237e-03, -9.4219e-02, -3.2651e-02, -6.4537e-02, -8.7075e-02,\n",
       "          -1.0160e-01, -1.0664e-01, -8.9282e-03, -6.0058e-03,  1.1639e-02,\n",
       "           1.5756e-02, -3.5794e-03, -6.3199e-02, -1.2983e-02, -9.4255e-02,\n",
       "           8.5799e-03, -4.4803e-02,  9.4317e-02,  4.9931e-03,  8.4904e-02,\n",
       "          -4.3418e-02, -7.2803e-02, -6.9527e-02, -1.2208e-01,  2.3480e-02,\n",
       "           8.1376e-02,  1.0939e-02,  5.7722e-02, -1.6694e-02,  2.5600e-02,\n",
       "          -6.6898e-02, -6.5225e-02,  1.2312e-02,  3.2072e-02,  4.5146e-02,\n",
       "          -1.5811e-01, -9.6129e-02, -7.9831e-02,  6.3505e-02, -9.0888e-02,\n",
       "           3.6898e-02,  1.7505e-02, -1.6032e-01,  9.5275e-02,  3.1000e-02,\n",
       "           2.2275e-02, -1.0020e-01, -5.6777e-02, -4.7073e-02,  6.5647e-02,\n",
       "           6.5942e-02, -8.6407e-02,  1.2402e-02,  8.7614e-02,  8.3828e-02,\n",
       "           4.8072e-02, -1.4171e-01, -2.8771e-02,  1.0936e-01, -3.6305e-02,\n",
       "           6.6808e-03, -6.3204e-02, -5.8300e-05,  2.9364e-02,  1.2031e-01,\n",
       "           2.9397e-02,  4.4510e-02,  8.3775e-02, -8.9414e-02,  2.6133e-02,\n",
       "          -1.3797e-01, -6.8469e-02, -7.2729e-02,  8.9034e-02,  2.3183e-02,\n",
       "           2.0144e-02, -3.8559e-03,  5.4321e-02, -1.3240e-02,  2.2467e-03,\n",
       "          -4.8309e-02,  6.8505e-02,  2.1767e-02,  8.8430e-02,  1.3368e-01,\n",
       "          -2.5194e-02,  7.9789e-02, -5.0613e-02, -4.7165e-02,  4.0300e-02,\n",
       "          -5.2658e-02,  2.3203e-03,  5.4806e-02,  1.1837e-01, -6.2227e-02,\n",
       "           1.6562e-02, -1.5006e-02,  1.0936e-02,  5.2184e-02, -4.1145e-02,\n",
       "           3.7758e-02,  3.9833e-02,  1.0966e-01,  1.0824e-01, -7.7938e-03,\n",
       "           1.0018e-01, -4.1260e-02,  1.2112e-01],\n",
       "         [-9.8425e-02,  2.9972e-02, -1.2636e-01, -6.2080e-02, -1.7895e-02,\n",
       "           8.4695e-02,  9.4699e-02, -3.5569e-02,  1.6306e-02, -7.2529e-02,\n",
       "          -9.0952e-02,  1.2569e-01,  1.0650e-01, -2.3397e-02, -1.0499e-02,\n",
       "           1.5913e-02,  1.8736e-03, -3.5050e-02,  1.6653e-01,  3.0529e-02,\n",
       "           4.9394e-03, -8.5510e-02, -1.2596e-02, -7.2623e-02, -7.8194e-02,\n",
       "          -6.0527e-02, -9.0167e-02, -5.0985e-02,  4.2283e-02,  1.4709e-02,\n",
       "           4.3052e-02,  6.6643e-02, -4.3615e-02,  2.4058e-02, -8.8901e-02,\n",
       "           1.0712e-02, -5.1989e-02,  8.0734e-02, -9.3982e-03,  8.4532e-02,\n",
       "          -2.4608e-02, -2.8801e-02, -5.0691e-02, -7.3589e-02,  2.3429e-02,\n",
       "           2.8723e-02, -2.1657e-02,  3.1841e-02, -2.3919e-02,  3.7171e-02,\n",
       "          -1.1427e-02, -6.5257e-02, -1.0052e-02,  3.1718e-02,  5.5516e-02,\n",
       "          -1.2096e-01, -9.8019e-02, -5.4888e-02,  7.2466e-02, -1.0602e-01,\n",
       "           8.1455e-02, -5.6702e-02, -1.2096e-01,  9.2402e-02,  3.1068e-02,\n",
       "           3.3962e-02, -6.7404e-02, -7.1648e-02, -2.6583e-02,  6.7678e-02,\n",
       "           7.7153e-02, -6.2637e-02,  1.7519e-02,  5.8396e-02,  9.7065e-02,\n",
       "           2.0137e-02, -1.2836e-01, -2.9153e-02,  7.1401e-02, -3.6360e-02,\n",
       "          -1.9997e-02, -6.6983e-02,  3.2140e-02,  1.2371e-02,  1.0978e-01,\n",
       "           5.9999e-02,  3.0378e-02,  4.3276e-02, -9.6605e-02,  6.2700e-02,\n",
       "          -5.9179e-02, -9.7422e-02, -1.7380e-02,  1.0445e-01, -2.4758e-02,\n",
       "          -3.3081e-03, -3.2627e-02,  5.4218e-02, -5.3976e-02, -3.8682e-02,\n",
       "          -4.8315e-02,  9.4259e-02,  3.4221e-02,  9.8283e-02,  8.6082e-02,\n",
       "          -1.4257e-02,  1.0579e-01, -2.6469e-02, -3.8226e-02,  3.9521e-02,\n",
       "          -6.1362e-02, -4.5445e-03,  4.7301e-02,  6.4813e-02, -4.1345e-02,\n",
       "           5.2384e-03, -1.5085e-02,  1.0954e-02,  1.7078e-02, -8.9696e-03,\n",
       "           6.3586e-02, -7.4373e-03,  1.0537e-01,  9.1948e-02, -1.4883e-02,\n",
       "           7.9281e-02, -7.3749e-02,  1.3506e-01]]], grad_fn=<ViewBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. RealmForOpenQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import RealmForOpenQA, RealmRetriever, AutoTokenizer \n",
    "\n",
    "model_name = \"google/realm-orqa-nq-openqa\"\n",
    "\n",
    "retriever = RealmRetriever.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = RealmForOpenQA.from_pretrained(model_name, retriever)\n",
    "\n",
    "question = \"Who is the pioneer in modern computer science?\"\n",
    "question_ids = tokenizer([question], return_tensors=\"pt\")\n",
    "answer_ids = tokenizer(\n",
    "    [\"alan mathison turing\"],\n",
    "    add_special_tokens=False,\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=False,\n",
    ").input_ids\n",
    "\n",
    "reader_output, predicted_answer_ids = model(**question_ids, answer_ids = answer_ids, return_dict = False)\n",
    "predicted_answer = tokenizer.decode(predicted_answer_ids)\n",
    "loss = reader_output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
